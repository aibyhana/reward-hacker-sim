# ğŸ§  RewardHackerSim

**RewardHackerSim** is a simple and visual Python project that simulates reward hacking in reinforcement learning. It showcases how an RL agent might exploit flawed reward functions, a core challenge in AI alignment and safety research.

---

## ğŸ“Œ What It Does

- Trains a basic Q-learning agent in a toy gridworld
- Introduces a reward vulnerability (a high-reward â€œhack tileâ€)
- Detects abnormal agent behavior exploiting the loophole
- Visualizes training performance and agent movement with plots

---

## ğŸ§ª Key Results

| No Hack Detected | With Reward Hack Enabled |
|------------------|--------------------------|
| ![Reward No Hack](reward_no_hack.png) | ![Reward With Hack](reward_with_hack.png) |
| ![Heatmap No Hack](heatmap_no_hack.png) | ![Heatmap With Hack](heatmap_with_hack.png) |

âœ… When the hack is disabled, the agent learns slowly and doesnâ€™t accumulate much reward.

âš ï¸ When the hack is enabled, the agent quickly identifies and exploits the vulnerability, leading to inflated reward loops.

---

## ğŸ›  How to Run

```bash
git clone https://github.com/yourusername/reward-hacker-sim.git
cd reward-hacker-sim
pip install numpy matplotlib
python main.py
